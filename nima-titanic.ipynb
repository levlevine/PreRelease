{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_kg_hide-input": false,
    "execution": {
     "iopub.execute_input": "2023-06-13T19:41:53.936073Z",
     "iopub.status.busy": "2023-06-13T19:41:53.935597Z",
     "iopub.status.idle": "2023-06-13T19:41:53.950428Z",
     "shell.execute_reply": "2023-06-13T19:41:53.949548Z",
     "shell.execute_reply.started": "2023-06-13T19:41:53.936001Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/titanic/train.csv\n",
      "/kaggle/input/titanic/test.csv\n",
      "/kaggle/input/titanic/gender_submission.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.model_selection import train_test_split\n",
    "  \n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-13T19:41:53.976675Z",
     "iopub.status.busy": "2023-06-13T19:41:53.976321Z",
     "iopub.status.idle": "2023-06-13T19:41:53.991919Z",
     "shell.execute_reply": "2023-06-13T19:41:53.990724Z",
     "shell.execute_reply.started": "2023-06-13T19:41:53.976629Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
       "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\n",
    "train_data.head()\n",
    "train_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-13T19:41:53.994688Z",
     "iopub.status.busy": "2023-06-13T19:41:53.994359Z",
     "iopub.status.idle": "2023-06-13T19:41:54.009737Z",
     "shell.execute_reply": "2023-06-13T19:41:54.008839Z",
     "shell.execute_reply.started": "2023-06-13T19:41:53.994638Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "PassengerId0\n",
      "Survived0\n",
      "Pclass0\n",
      "Name0\n",
      "Sex0\n",
      "Age177\n",
      "SibSp0\n",
      "Parch0\n",
      "Ticket0\n",
      "Fare0\n",
      "Cabin687\n",
      "Embarked0\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "print(\"start\")\n",
    "#print how many nans in each columns\n",
    "train_data['Embarked'].dropna(inplace=True)\n",
    "\n",
    "for key in train_data.keys():\n",
    "    print(key + str(train_data[key].isna().sum()))\n",
    "    \n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into training and testing data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-13T19:41:54.020973Z",
     "iopub.status.busy": "2023-06-13T19:41:54.020138Z",
     "iopub.status.idle": "2023-06-13T19:41:54.065835Z",
     "shell.execute_reply": "2023-06-13T19:41:54.065028Z",
     "shell.execute_reply.started": "2023-06-13T19:41:54.020893Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Pclass        Age  SibSp  Parch     Fare  Youth  Embarked_C  Embarked_Q  \\\n",
      "0       3.0  22.000000    1.0    0.0   7.2500    0.0         0.0         0.0   \n",
      "1       1.0  38.000000    1.0    0.0  71.2833    0.0         1.0         0.0   \n",
      "2       3.0  26.000000    0.0    0.0   7.9250    0.0         0.0         0.0   \n",
      "3       1.0  35.000000    1.0    0.0  53.1000    0.0         0.0         0.0   \n",
      "4       3.0  35.000000    0.0    0.0   8.0500    0.0         0.0         0.0   \n",
      "..      ...        ...    ...    ...      ...    ...         ...         ...   \n",
      "886     2.0  27.000000    0.0    0.0  13.0000    0.0         0.0         0.0   \n",
      "887     1.0  19.000000    0.0    0.0  30.0000    0.0         0.0         0.0   \n",
      "888     3.0  29.699118    1.0    2.0  23.4500    0.0         0.0         0.0   \n",
      "889     1.0  26.000000    0.0    0.0  30.0000    0.0         1.0         0.0   \n",
      "890     3.0  32.000000    0.0    0.0   7.7500    0.0         0.0         1.0   \n",
      "\n",
      "     Embarked_S  Sex_female  Sex_male  \n",
      "0           1.0         0.0       1.0  \n",
      "1           0.0         1.0       0.0  \n",
      "2           1.0         1.0       0.0  \n",
      "3           1.0         1.0       0.0  \n",
      "4           1.0         0.0       1.0  \n",
      "..          ...         ...       ...  \n",
      "886         1.0         0.0       1.0  \n",
      "887         1.0         1.0       0.0  \n",
      "888         1.0         1.0       0.0  \n",
      "889         0.0         0.0       1.0  \n",
      "890         0.0         0.0       1.0  \n",
      "\n",
      "[891 rows x 11 columns]\n",
      "done splitting into test an train set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/opt/conda/lib/python3.6/site-packages/pandas/core/indexing.py:494: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "x= train_data[['Pclass', 'Sex', 'Age', 'SibSp','Parch', 'Fare', 'Embarked']]\n",
    "y=train_data[\"Survived\"]\n",
    "x['Youth'] = 0\n",
    "x.loc[x['Age'] <=16, 'Youth'] = 1\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "my_imputer = SimpleImputer()\n",
    "# Columns to be one-hot encoded\n",
    "columns_to_encode = [ 'Embarked', 'Sex']\n",
    "\n",
    "# Perform onefit-hot encoding\n",
    "one_hot_encoded = pd.get_dummies(x[columns_to_encode])\n",
    "\n",
    "# Remove the original columns\n",
    "df_encoded = x.drop(columns_to_encode, axis=1)\n",
    "\n",
    "\n",
    "# Concatenate the one-hot encoded columns to the modified DataFrame\n",
    "df_encoded = pd.concat([df_encoded, one_hot_encoded], axis=1)\n",
    "column = list(df_encoded.keys())\n",
    "df_encoded = my_imputer.fit_transform(df_encoded)\n",
    "df_encoded = pd.DataFrame(df_encoded, columns = column)\n",
    "\n",
    "print(df_encoded)\n",
    "# using the train test split function\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_encoded,y ,\n",
    "                                   random_state=1, \n",
    "                                   test_size=0.001, \n",
    "                                   shuffle=True)\n",
    "\n",
    "\n",
    "print(\"done splitting into test an train set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-13T19:41:54.067448Z",
     "iopub.status.busy": "2023-06-13T19:41:54.067188Z",
     "iopub.status.idle": "2023-06-13T19:41:54.099285Z",
     "shell.execute_reply": "2023-06-13T19:41:54.098445Z",
     "shell.execute_reply.started": "2023-06-13T19:41:54.067395Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "Accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your test was successfully saved!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE()\n",
    "print(\"1\")\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "scaler = StandardScaler()\n",
    "standardized_data = scaler.fit_transform(X_resampled)\n",
    "lda = LDA()\n",
    "print(\"1\")\n",
    "\n",
    "lda.fit(standardized_data, y_resampled)\n",
    "# Make predictions on the testing data\n",
    "x_test_standardized = scaler.transform(X_test)\n",
    "print(\"1\")\n",
    "\n",
    "y_pred = lda.predict(x_test_standardized)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "\n",
    "output = pd.DataFrame({ 'Survived': y_pred})\n",
    "output.to_csv('test_results.csv', index=False)\n",
    "print(\"Your test was successfully saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-13T19:41:54.101871Z",
     "iopub.status.busy": "2023-06-13T19:41:54.101594Z",
     "iopub.status.idle": "2023-06-13T19:41:54.127205Z",
     "shell.execute_reply": "2023-06-13T19:41:54.126176Z",
     "shell.execute_reply.started": "2023-06-13T19:41:54.101825Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before moving on, make sure that your code returns the output above.  The code above calculates the percentage of female passengers (in **train.csv**) who survived.\n",
    "\n",
    "Then, run the code below in another code cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_kg_hide-output": false,
    "execution": {
     "iopub.execute_input": "2023-06-13T19:41:54.130088Z",
     "iopub.status.busy": "2023-06-13T19:41:54.129681Z",
     "iopub.status.idle": "2023-06-13T19:41:54.183736Z",
     "shell.execute_reply": "2023-06-13T19:41:54.182723Z",
     "shell.execute_reply.started": "2023-06-13T19:41:54.130003Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Pclass        Age  SibSp  Parch      Fare     Youth  Embarked_C  \\\n",
      "0       3.0  34.500000    0.0    0.0    7.8292  0.112233         0.0   \n",
      "1       3.0  47.000000    1.0    0.0    7.0000  0.112233         0.0   \n",
      "2       2.0  62.000000    0.0    0.0    9.6875  0.112233         0.0   \n",
      "3       3.0  27.000000    0.0    0.0    8.6625  0.112233         0.0   \n",
      "4       3.0  22.000000    1.0    1.0   12.2875  0.112233         0.0   \n",
      "..      ...        ...    ...    ...       ...       ...         ...   \n",
      "413     3.0  29.699118    0.0    0.0    8.0500  0.112233         0.0   \n",
      "414     1.0  39.000000    0.0    0.0  108.9000  0.112233         1.0   \n",
      "415     3.0  38.500000    0.0    0.0    7.2500  0.112233         0.0   \n",
      "416     3.0  29.699118    0.0    0.0    8.0500  0.112233         0.0   \n",
      "417     3.0  29.699118    1.0    1.0   22.3583  0.112233         1.0   \n",
      "\n",
      "     Embarked_Q  Embarked_S  Sex_female  Sex_male  \n",
      "0           1.0         0.0         0.0       1.0  \n",
      "1           0.0         1.0         1.0       0.0  \n",
      "2           1.0         0.0         0.0       1.0  \n",
      "3           0.0         1.0         0.0       1.0  \n",
      "4           0.0         1.0         1.0       0.0  \n",
      "..          ...         ...         ...       ...  \n",
      "413         0.0         1.0         0.0       1.0  \n",
      "414         0.0         0.0         1.0       0.0  \n",
      "415         0.0         1.0         0.0       1.0  \n",
      "416         0.0         1.0         0.0       1.0  \n",
      "417         0.0         0.0         0.0       1.0  \n",
      "\n",
      "[418 rows x 11 columns]\n",
      "done splitting into test an train set\n",
      "     PassengerId  Survived\n",
      "0            892         0\n",
      "1            893         1\n",
      "2            894         0\n",
      "3            895         0\n",
      "4            896         1\n",
      "..           ...       ...\n",
      "413         1305         0\n",
      "414         1306         1\n",
      "415         1307         0\n",
      "416         1308         0\n",
      "417         1309         0\n",
      "\n",
      "[418 rows x 2 columns]\n",
      "Your submission was successfully saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/pandas/core/indexing.py:376: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/opt/conda/lib/python3.6/site-packages/pandas/core/indexing.py:494: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "x_test= test_data[['Pclass', 'Sex', 'Age', 'SibSp','Parch', 'Fare', 'Embarked']]\n",
    "y_test=train_data[\"Survived\"]\n",
    "x_test.loc[x_test['Age'] <=16, 'Youth'] = 1\n",
    "\n",
    "# Columns to be one-hot encoded\n",
    "columns_to_encode = [ 'Embarked', 'Sex']\n",
    "\n",
    "# Perform onefit-hot encoding\n",
    "one_hot_encoded_test = pd.get_dummies(x_test[columns_to_encode])\n",
    "\n",
    "# Remove the original columns\n",
    "df_encoded_test = x_test.drop(columns_to_encode, axis=1)\n",
    "\n",
    "\n",
    "# Concatenate the one-hot encoded columns to the modified DataFrame\n",
    "df_encoded_test= pd.concat([df_encoded_test, one_hot_encoded_test], axis=1)\n",
    "df_encoded_test = df_encoded_test.reindex(columns = df_encoded.columns, fill_value=0)\n",
    "\n",
    "column = list(df_encoded_test.keys())\n",
    "df_encoded_test = my_imputer.transform(df_encoded_test)\n",
    "df_encoded_test = pd.DataFrame(df_encoded_test, columns = column)\n",
    "\n",
    "print(df_encoded_test)\n",
    "df_encoded_test  = scaler.transform(df_encoded_test)\n",
    "print(\"done splitting into test an train set\")\n",
    "predictions = lda.predict(df_encoded_test)\n",
    "\n",
    "output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\n",
    "output.to_csv('submission.csv', index=False)\n",
    "print(output)\n",
    "print(\"Your submission was successfully saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-13T19:48:01.874142Z",
     "iopub.status.busy": "2023-06-13T19:48:01.873618Z",
     "iopub.status.idle": "2023-06-13T19:48:01.917545Z",
     "shell.execute_reply": "2023-06-13T19:48:01.916329Z",
     "shell.execute_reply.started": "2023-06-13T19:48:01.874039Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     PassengerId  Survived\n",
      "0            892         0\n",
      "1            893         0\n",
      "2            894         0\n",
      "3            895         0\n",
      "4            896         0\n",
      "..           ...       ...\n",
      "413         1305         0\n",
      "414         1306         1\n",
      "415         1307         0\n",
      "416         1308         0\n",
      "417         1309         0\n",
      "\n",
      "[418 rows x 2 columns]\n",
      "Your submission was successfully saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(standardized_data, y_resampled)\n",
    "\n",
    "predictions = clf.predict(df_encoded_test)\n",
    "output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\n",
    "output.to_csv('submission_random_forest.csv', index=False)\n",
    "print(output)\n",
    "print(\"Your submission was successfully saved!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
